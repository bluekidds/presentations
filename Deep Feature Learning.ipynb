{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:ed04ec2e7a61e5d22f3119e8d3cfbdcdcb9fd7d42805c091fe1e7e552342f932"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Deep Feature Learning in Vision Applications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Author: Fu-Chun Hsu"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Motivation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###Two Most Important Fields in Machine Learning:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      " \n",
      " * Feature \n",
      "    * Design useful features to discover patterns in data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      " * Learning Algorithm:\n",
      "     * Methods to learn model from features in specific tasks."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### From Feature Learning to **Representation Learning**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In last decade, almost all famous solutions in vision generate features by hands:\n",
      "\n",
      " * HOG (Histogram of Oriented Gradients) [2005 Dalal CVPR]\n",
      " * SIFT (Scale-invariant feature transform) [2004 Lowe IJCV]\n",
      " * GLOH (Gradient Location and Orientation Histogram) [2005 Mikolajczyk PAMI]\n",
      " * etc..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "![handcraft](figures/handcraft.png)\n",
      "\n",
      "[*Andrew Ng, Tutorial in Deep Learning*]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### *Think* like brain:\n",
      "![](figures/brain.jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Deep Neural Network:\n",
      "<img src=\"figures/simple.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "### Why Deep Architecture?\n",
      "\n",
      " * More abstract concepts are collected. \n",
      " * When number of layers grows, less parameters are used.\n",
      " * More interesting intermediate(hidden) features are found.\n",
      " * Non-linear transformation functions approximate the manifold.\n",
      " \n",
      " [*Bengio*, \"*Learning Deep Architectures for AI*\", 2009, *Foundations and Trends in Machine Learning*]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Key to Success of Deep Neural Network\n",
      "\n",
      " * Greedy-Layer Pre-training [Hinton, 2006, Science]\n",
      " * Unsupervised Feature Learning [Erhan , 2010, JMLR]\n",
      " * Convolutional Neural Network [Lecun, 1989, Neural Computation]\n",
      " * Variants of non-Linearities [Jarrett, 2009, ICCV]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Greedy Layer-Wise Pre-training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "![](figures/greedy.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "[2007 Bengio, NIPS] \n",
      " \n",
      " * Hinton first introduce layer-wise RBF pre-trianing\n",
      " * Bengio extended to layer-wise Autoencoder\n",
      "<img src=\"figures/ae_easy.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$P(X) = sigm(c + W*sigm(b + W'))$$\n",
      "\n",
      " * Avoid poor solution from random initialization\n",
      " * Gives good initialization of the parameters\n",
      " * Refine with supervised fine-tuning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### With pre-training:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Feature numbers required drops.\n",
      "![Number of features before pre-training(Left) and after(Right](figures/num_features.png)\n",
      "\n",
      "[Figure: Number of features before pre-training(Left) and after(Right)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Generalization Errors drops.\n",
      "![](figures/histogram_pretraining.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Visualization \n",
      "\n",
      "### Before Pre-training\n",
      "![](figures/compare_before.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### After Pre-training\n",
      "![](figures/compare_after.png)\n",
      "\n",
      "[[Erhan, et.al, *Why Does Unsupervised Pre-training Help Deep Learning?* , 2010, JMLR]]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Therefore, we can concentrate on the design of *single* layer feature."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "### First, features can be self-taught\n",
      "![](figures/self_taught.png)\n",
      "\n",
      "[Raina,. \"*Self-taught learning: transfer learning from unlabeled data.*\" ICML, 2007.]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "### Second, different regularization produces variants of features:\n",
      "\n",
      " * Weight-Decay Autoencoder[Raina, ICML, 2007]:\n",
      "     ![](figures/weight_decay.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      " * Denoising Autoencoder[Vincent, JMLR, 2010]\n",
      " ![](figures/denoise.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      " * Contractive Autoencoder[Rifai, ICML, 2011]:\n",
      " ![](figures/contractive.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      " * Sparse Autoencoder[Lee, ICML, 2011]\n",
      " ![](figures/sae.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Convolutional Neural Network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      " * Only successful deep algorithm before 2006.\n",
      " * Powerful especially in vision task."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      " * Three advantages using CNN:\n",
      "     * Selective Filters -- reduce parameters\n",
      "     * Translational Invariance -- spatial pooling\n",
      "     * Capability of adding non-linear components\n",
      " ![CNN](figures/CNN.png)\n",
      " \n",
      " [*Jarrett*, \"*What is the Best Multi-Stage Architecture for Object Recognition?*, ICCV, 2009\"]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Non-Linearity Add-Ons"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "* Without non-linearity functions, always linear no matter how deep.\n",
      "* Linear Autoencoder -> *Principal Component Analysis*\n",
      "* Three non-linear modules frequently seen."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "### Activation Function:\n",
      "\n",
      " * $h_{w,b}x = f(W^T*x)$ -- $ f(x)$ is activation unit\n",
      "     * Sigmoid\n",
      "     * Tanh\n",
      "     * RELu - Rectified Linear Unit\n",
      " ![](figures/activate.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "  * Spatial Subsampling -- *Pooling*\n",
      "      * Average Pooling: $f_{av} = \\frac{1}{P}\\sum_{i=1}^P{v_i}$\n",
      "      * Max Pooling: $f_{max} = max_i v_i$\n",
      "  ![](figures/pooling.jpeg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      " * Local Contrast Normalization (LCN)\n",
      "     * Improves performance significantly\n",
      "     \n",
      " $v_{ijk} = x_{ijk} - \\sum_{ipq} w_{pq} * x_{i,j+p,k+q}$ , $w_{pq}$ is average or Gaussian kernel.\n",
      " \n",
      " $y_{ijk} = \\frac{v_{ijk}}{\\sigma_{jk}}$ \n",
      " \n",
      " ![](figures/lcn.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Head Detection Via AutoEncoder Feature Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "![](figures/head_Detection.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      " * Features are learned through a sparse autoencoder\n",
      " * Different preprocessing employed on motion features\n",
      " * Feature-based Receptive Field Learning"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Thank You"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}